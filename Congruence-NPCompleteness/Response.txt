Dear editors and reviewers,

We thank you for your positive evaluation of our paper and your comments.

Below is a list of changes made to address the reviewers' comments.


============================

Reviewer #1: 


> Abstract: we provide here an NP-hardness proof --> by reading the abstract
>          one could understand that the paper does not prove the problem
>          to be in NP. I would replace hardness by completeness.

Done.


> Page 2, line 45: polynomial time algorithm --> polynomial-time algorithm

Fixed.

> Page 3, line 2: this short paper --> this paper

Done.


> Page 5: when explaining the congruence graph, I would add a small
>        example with a figure including the resulting congruence graph

This was indeed lacking.  Fixed.

> Page 5, line 46: as far as I know, explanation production can only be
>        done in time O(k \alpha(k,k)) for a proof with k literals.

The sentence "the explanation production is linear with respect to the
explanation size" was indeed a bit bold.  We are now more precise, explicitly
referring to the work of Nieuwenhuis and Oliveras for details.

Our implementation in veriT might be linear, but to state it, a proof would be needed, with a precise description of the algorithm, and this is outside the scope of the paper.


> Page 7, Definition 7: the star in Assignment might confuse the reader
>        since it is very similar to the asterisk in the congruence
>        definition. I would use another symbol.

Indeed the overload is possibly confusing and unnecessary.  We changed Assignment* to AssignmentEqs.

> Page 9, line 19: cardinality constraint on the explanation -->
>                 cardinality constraint on the explanation size

Done.


> Page 9, Lemma 3: it would improve the readability to include an
>        extension of Figure 4 (or a figure similar to it) where the
>        tautological clauses are depicted.

Good suggestion.
We added such an example and two figures.
We also rewrote the proof to improve clarity.
TODO: proof read the proof

> Page 10, line 36: Roberto Nieuwenhuis --> Robert Nieuwenhuis

Fixed.

> Page 11, line 5: Jovanovi --> Jovanovic

Fixed.


==========================

Reviewer #2: 


> Generally lemma 3 is the most important in the article, 
> but in contrast to other parts of the article, it goes too fast. 
> There is a crucial point there about enforcing each variable x to 
> be exactly one of T or F, via an additional cardinality constraint 
> and tautological clauses (x \/ !x). But it is not clear to me how 
> this cardinality constraint looks like in EUF. It seems that what 
> they want to achieve is 
>
> (x = T) + (x = F) = 1, 
>
> and they do it by adding 
>
> (x = T) + (x = F) <= 1 
>
> together with 
>
> (x = T) \/ (X = F).
>
> If yes, then how does the cardinality constraint fall into 
> the conjunctive fragment of EUF? 

The cardinality constraint is not part of the encoded problem.
It is part of the proof as one side of the if and only if statement.
When the cardinality constraint |E'| <= 3n + 4m - 1 is assumed (together with the structure of E' and the congruence closure problem), 
it follows that either (x = T) or (x = F) is in an explanation.

We rewrote the proof to clarify this issue and improve clarity in general.

> Also, why isn't the inequality sufficient? (i.e., why enforce a full assignment ? ).

We need to have equality in order to rule out sets of equations as explanations that have x=T and x=F in them,
and thereby do not correspond to assignments.
We added an example right after the proof of Lemma 3 making this argument explicit.
  
> abstract: "'to our best knowledge' => 'to the best of our knowledge' 
> (see https://answers.yahoo.com/question/index?qid=20130720053631AAXDsHg)

Fixed.

> p 2: 'searching for short paths' => did you mean shortest paths ? 

Yes and no.
We used an adaptation of a shortest path algorithm, but since the weights of the graph dynamically changed, 
we were not guaranteed to construct shortest paths in the final graph.
It is beyond the scope of this paper to describe this method in detail.
However, we re-wrote the paragraph to make the method more explicit.

TODO: @Bruno look at Andreas' changes to this
Bruno's comment: you seem to conclude that the NP-completeness is a negative answer to whether the dynamically weighted shortest path algorithm can find the shortest path. But this conclusion is only possible if you additionally argue/mention that the dynamically weighted shortest path algorithm is polynomial-time. Is it? If so, this has to be mentioned in your paragraph.


> p 4: Def 2: is 'compatible' a standard term ? I always saw 'congruent'. 

Yes, it is a standard term. See, for instance:
https://en.wikipedia.org/wiki/Quotient_algebra#Compatible_relation
https://en.wikipedia.org/wiki/Congruence_relation
(and the algebra books referrenced there.)

We suspect that "compatible" is the original term from Mathematics, where a congruence relation is defined as: an equivalence relation that is also compatible. 

Also, replacing "compatible" by 'congruent' would lead to an apparently circular definition: a congruence relation is an equivalence relation that is also 'congruent'.

For these two reasons, we consider it more appropriate to use the term "compatible" than the term "congruent" to refer to that particular axiom, even if "congruent" might be more common in some communities.


> "(identity of two terms can be checked in
> constant time), and identity of two function symbols can be checked in constant
> time." since functions are terms then isn't this repetitive ? 

As entailed by our definition 1, 
we use the usual terminology of first-order logic. 
A term is either a constant/variable symbol or an 
n-ary function symbol applied to n terms. 
Therefore, a function symbol is generally not a term, except in the 
case of nullary function symbols (i.e. constants). 

Nevertheless, we agree that the sentence was not optimal. We improved it to:

"terms are DAGs with maximal
sharing (i.e. identity of atomic symbols and complex terms can be checked in constant time)"


> p 6: the sentence 'One could hope...' indeed raises the hopes that with 
> such redundance it can be achieved. Perhaps you can show an example that 
> demonstrates why this intuition is wrong ? 

This would require us to define more precisely the naive ideas that might lead one to hope that, in order to show some examples why those naive ideas do not always result in the shortest explanation. But the benefit of doing that would not be worth the distraction that it would cause.

Nevertheless, we have slightly reformulated that paragraph to better convey the message that the hope is naive. The new paragraph is reproduced below:

"One could (naively) hope to conceive a different
congruence closure algorithm generating the smallest explanation in polynomial
time. For example, one might attempt to modify the iterative removal algorithm; or attempt to modify shortest path algorithms and apply them to congruence graphs enriched with redundant equations as labels. However, such attempts would be futile. As proven in the next section, the corresponding decision problem is NP-hard. "



> p 8: The bottom dotted edge on the left is wrong? (t1(x3) --- t1(\bot_3))

Well spotted.
Fixed.

> Please use \qed at the end of proofs. 

Fixed

==========================

Reviewer #3: 


> p3, 2: "short paper" -> "short article"

Fixed to "article". Reviewer 1 requested the removal of "short"


> p3, 30: "null arity" -> "arity zero", or "zero-ary"/"nullary"

Fixed to "nullary".


> p4, 13: the empty set is not a congruence relation, the authors
> probably mean the diagonal set { (x, x) | x in T }

Fixed

> p5, 20: for functions of arity > 1, congruence edges have to be
> labeled with a vector of equalities

The label of a congruence edge is the equality itself, 
e.g. if there is a congruence edge between terms f(a,b) and f(c,d), then the label is f(a,b) = f(c,d).
It is also an option to use explanations as labels, e.g. <a=c,b=d>.
However, there can be multiple explanations for a congruence edge.
Ideally, we would like to label it with the shortest one, but we do not know which is the shortest one before solving the problem.
If we would know, a shortest path algorithm could find shortest explanations, if the weights correspond to sizes of explanations.

> p5, 21: "logic" -> "logical"

Fixed.
